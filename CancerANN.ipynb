{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3235880e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "5         M        12.45         15.70           82.57      477.1   \n",
       "6         M        18.25         19.98          119.60     1040.0   \n",
       "7         M        13.71         20.83           90.20      577.9   \n",
       "8         M        13.00         21.82           87.50      519.8   \n",
       "9         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "5         0.2087  ...         15.47          23.75           103.40   \n",
       "6         0.1794  ...         22.88          27.66           153.20   \n",
       "7         0.2196  ...         17.06          28.14           110.60   \n",
       "8         0.2350  ...         15.49          30.73           106.20   \n",
       "9         0.2030  ...         15.09          40.68            97.65   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "5       741.6            0.1791             0.5249           0.5355   \n",
       "6      1606.0            0.1442             0.2576           0.3784   \n",
       "7       897.0            0.1654             0.3682           0.2678   \n",
       "8       739.3            0.1703             0.5401           0.5390   \n",
       "9       711.4            0.1853             1.0580           1.1050   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "5                0.1741          0.3985                  0.12440  \n",
       "6                0.1932          0.3063                  0.08368  \n",
       "7                0.1556          0.3196                  0.11510  \n",
       "8                0.2060          0.4378                  0.10720  \n",
       "9                0.2210          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "dataset=pd.read_csv(\"bvmcancer.csv\")\n",
    "dataset.drop(dataset.columns[[0,32]],axis=1,inplace=True)\n",
    "np.random.seed(55)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a0e3d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
     ]
    }
   ],
   "source": [
    "x=dataset.iloc[:,1:].values\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53fd058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'B' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M'\n",
      " 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'M' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'M' 'M' 'B' 'B'\n",
      " 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B'\n",
      " 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'B'\n",
      " 'M' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'B'\n",
      " 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'M'\n",
      " 'M' 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B'\n",
      " 'M' 'M' 'M' 'B' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'M' 'M'\n",
      " 'M' 'M' 'B' 'M' 'M' 'M' 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'M' 'M'\n",
      " 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'M'\n",
      " 'B' 'B' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'M'\n",
      " 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'B'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B'\n",
      " 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'B' 'M'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'B' 'M'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'M' 'M' 'B']\n"
     ]
    }
   ],
   "source": [
    "y=dataset.iloc[:,0].values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673d49ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
      " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y=LabelEncoder()\n",
    "y=labelencoder_y.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c526c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d11b3cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.85189846  1.81243805  1.84719821 ...  1.59086136  0.64298133\n",
      "  -0.40633689]\n",
      " [ 0.09575123 -0.56566089 -0.02391154 ... -1.23476037 -0.69341836\n",
      "  -1.21488847]\n",
      " [-0.32619954 -0.71058001 -0.36536751 ... -0.85458242  1.19036275\n",
      "  -0.711148  ]\n",
      " ...\n",
      " [ 0.14923795  1.37530498  0.2136418  ...  0.11955561  0.50490313\n",
      "   0.98296008]\n",
      " [-0.05876596 -1.40904263 -0.12048494 ... -0.85116439 -0.09343572\n",
      "  -0.8544627 ]\n",
      " [ 3.99731014  1.67939755  4.14081662 ...  2.32573742 -0.39260515\n",
      "  -0.51596194]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a05fe24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 5s 4ms/step - loss: 0.1837 - accuracy: 0.9347\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0737 - accuracy: 0.9749\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9849\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9849\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9874\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9899\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9950\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9925\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9975\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9975\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9925\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9774\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9975\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 8.1676e-04 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 6.5416e-04 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 5.7487e-04 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 4.7112e-04 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.0949e-04 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 3.4296e-04 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.0870e-04 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.6899e-04 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.3940e-04 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.1357e-04 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.9482e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.7234e-04 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.5100e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.4042e-04 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2555e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1925e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.0660e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 9.5320e-05 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 8.9959e-05 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 8.2196e-05 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 7.2401e-05 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.9094e-05 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 6.1916e-05 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 5.9024e-05 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 5.3513e-05 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 5.3151e-05 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.6616e-05 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.3200e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.0647e-05 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 3.7437e-05 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 3.5418e-05 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.3277e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0925e-05 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9060e-05 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6866e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4898e-05 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3333e-05 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2901e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1051e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9584e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.8187e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.7270e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.6219e-05 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.4916e-05 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.4609e-05 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.3808e-05 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.2430e-05 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.2333e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.1949e-05 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.0568e-05 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.0109e-05 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 9.4664e-06 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 8.9681e-06 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 8.4085e-06 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 7.9534e-06 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 7.5163e-06 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 7.1981e-06 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 6.6568e-06 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 6.3201e-06 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 5.7986e-06 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 5.6433e-06 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 5.2449e-06 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 5.0497e-06 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.7611e-06 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.5660e-06 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.3499e-06 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0402e-06 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.8486e-06 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.7511e-06 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.4354e-06 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.4762e-06 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0390e-06 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.0638e-06 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.7820e-06 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.6089e-06 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.5220e-06 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.3712e-06 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.2650e-06 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.1045e-06 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.0026e-06 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.9184e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d876f8aca0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model=Sequential()\n",
    "model.add(Dense(128,input_dim=30,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,batch_size=5,epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65545c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 3s 5ms/step - loss: 0.6161 - accuracy: 0.7889\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.9095\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.9246\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.9372\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2212 - accuracy: 0.9447\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1845 - accuracy: 0.9497\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9548\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1410 - accuracy: 0.9623\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.9598\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1172 - accuracy: 0.9648\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9648\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9673\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9673\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9698\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0874 - accuracy: 0.9724\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9749\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9749\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9774\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9774\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9774\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9799\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9824\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9824\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9849\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9824\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9849\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9849\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9824\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9849\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9849\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9849\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9849\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9849\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0534 - accuracy: 0.9849\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0524 - accuracy: 0.9849\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9849\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9849\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9849\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0484 - accuracy: 0.9849\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0475 - accuracy: 0.9849\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9849\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9824\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9849\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9874\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9874\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9874\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9874\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9874\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 0.9874\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9899\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9874\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9874\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9874\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9874\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9899\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9899\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9874\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9899\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 0.9899\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9899\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9899\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9899\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9899\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9899\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9899\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0278 - accuracy: 0.9899\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 0.9899\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 0.9925\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9899\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9925\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9925\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9950\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9950\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9950\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9950\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9950\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9950\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9950\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9950\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9950\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9975\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9950\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9950\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9950\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9975\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9950\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9975\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9975\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9950\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9975\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9950\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9950\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9975\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9975\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9975\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9975\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 0.9975\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9975\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9975\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d878283940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model=Sequential()\n",
    "model.add(Dense(128,input_dim=30,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,batch_size=10,epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9059193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 6s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred =model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "768162bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "results=confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9311788c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  0 102]\n",
      " [  0  69]]\n",
      "Accuracy Score :\n",
      "0.40350877192982454\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       102\n",
      "           1       0.40      1.00      0.57        69\n",
      "\n",
      "    accuracy                           0.40       171\n",
      "   macro avg       0.20      0.50      0.29       171\n",
      "weighted avg       0.16      0.40      0.23       171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prakr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prakr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prakr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "print(\"Confusion Matrix\")\n",
    "print(results) \n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(\"Report:\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af480d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
